{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snapvx import *\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create new graph\n",
    "gvx = TGraphVX()\n",
    "\n",
    "#Use CVXPY syntax to define a problem\n",
    "x1 = Variable(1, name='x1')\n",
    "obj = square(x1)\n",
    "#Add Node 1 with the given objective, with the constraint that x1 <= 10\n",
    "gvx.AddNode(1, Objective=obj, Constraints=[x1 <= 10])\n",
    "\n",
    "#Similarly, add Node 2 with objective |x2 + 3|\n",
    "x2 = Variable(1, name='x2')\n",
    "obj2 = abs(x2 + 3)\n",
    "gvx.AddNode(2, obj2, [])\n",
    "\n",
    "#Add an edge between the two nodes, \n",
    "#Define an objective, constraints using CVXPY syntax\n",
    "gvx.AddEdge(1, 2, Objective=square(norm(x1 - x2)), Constraints=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Optimal\n",
      "Total Objective: 2.500335\n",
      "Node 1:\n",
      "  x1 [-0.51706729]\n",
      "Node 2:\n",
      "  x2 [-1.02366535]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Solve the problem, and print the solution\n",
    "gvx.Solve()\n",
    "print gvx.PrintSolution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def laplace_reg(src, dst, data):\n",
    "    return (e_pen*sum_squares(src['x'] - dst['x']), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_loss_calculator(gvx,num_nodes, x_dimension, train_per_node):\n",
    "    \n",
    "    train_loss = 0\n",
    "    # T1\n",
    "    for i in range(num_nodes):\n",
    "        if i <= 2:\n",
    "            x = gvx.GetNodeValue(i+1,'x')\n",
    "            for k in range(train_per_node):\n",
    "                w =  w1[i*train_per_node+k] \n",
    "                noise = noise1[i*train_per_node+k]\n",
    "    #             w = np.random.normal(0, 1, 50)\n",
    "    #             noise = np.random.normal(0, 0.1, 1)\n",
    "                y =  np.dot(a1[:x_dimension], w) + a1[x_dimension] + noise\n",
    "                #print(y)\n",
    "                pred_y = np.dot(x[:x_dimension], w) + x[x_dimension]\n",
    "                train_loss += square(pred_y - y)\n",
    "\n",
    "        else:\n",
    "            x = gvx.GetNodeValue(i+1,'x')\n",
    "\n",
    "            for k in range(train_per_node):\n",
    "                w =  w1[i*train_per_node+k] \n",
    "                noise = noise1[i*train_per_node+k]\n",
    "    #             w = np.random.normal(0, 1, 50)\n",
    "    #             noise = np.random.normal(0, 0.1, 1)\n",
    "                y =  np.dot(a2[:x_dimension], w) + a2[x_dimension] + noise\n",
    "                pred_y = np.dot(x[:x_dimension], w) + x[x_dimension]\n",
    "                train_loss += square(pred_y - y)\n",
    "    # T2            \n",
    "    for i in range(num_nodes):\n",
    "        if i < 2:\n",
    "            x = gvx.GetNodeValue(5+i+1,'x')\n",
    "\n",
    "            for k in range(train_per_node):\n",
    "                w =  w2[i*train_per_node+k] \n",
    "                noise = noise2[i*train_per_node+k]\n",
    "    #             w = np.random.normal(0, 1, 50)\n",
    "    #             noise = np.random.normal(0, 0.1, 1)\n",
    "                y =  np.dot(a1_2[:x_dimension], w) + a1_2[x_dimension] + noise\n",
    "                pred_y = np.dot(x[:x_dimension], w) + x[x_dimension]\n",
    "                train_loss += square(pred_y - y)\n",
    "\n",
    "        else:\n",
    "            x = gvx.GetNodeValue(5+i+1,'x')\n",
    "\n",
    "            for k in range(train_per_node):\n",
    "                w =  w2[i*train_per_node+k] \n",
    "                noise = noise2[i*train_per_node+k]\n",
    "    #             w = np.random.normal(0, 1, 50)\n",
    "    #             noise = np.random.normal(0, 0.1, 1)\n",
    "                y =  np.dot(a2_2[:x_dimension], w) + a2_2[x_dimension] + noise\n",
    "                pred_y = np.dot(x[:x_dimension], w) + x[x_dimension]\n",
    "                train_loss += square(pred_y - y)\n",
    "    # T3            \n",
    "    for i in range(num_nodes):\n",
    "        if i <= 2:\n",
    "            x = gvx.GetNodeValue(10+i+1,'x')\n",
    "\n",
    "            for k in range(train_per_node):\n",
    "                w =  w3[i*train_per_node+k] \n",
    "                noise =  noise3[i*train_per_node+k]\n",
    "    #             w = np.random.normal(0, 1, 50)\n",
    "    #             noise = np.random.normal(0, 0.1, 1)\n",
    "                y =  np.dot(a1_3[:x_dimension], w) + a1_3[x_dimension] + noise\n",
    "                pred_y = np.dot(x[:x_dimension], w) + x[x_dimension]\n",
    "                train_loss += square(pred_y - y)\n",
    "\n",
    "        else:\n",
    "            x = gvx.GetNodeValue(10+i+1,'x')\n",
    "\n",
    "            for k in range(train_per_node):\n",
    "                w =  w3[i*train_per_node+k] \n",
    "                noise =  noise3[i*train_per_node+k]\n",
    "    #             w = np.random.normal(0, 1, 50)\n",
    "    #             noise = np.random.normal(0, 0.1, 1)\n",
    "                y =  np.dot(a2_3[:x_dimension], w) + a2_3[x_dimension] + noise\n",
    "                pred_y = np.dot(x[:x_dimension], w) + x[x_dimension]\n",
    "                train_loss += square(pred_y - y)\n",
    "\n",
    "    print('Train Loss: ' , train_loss.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test performance via total loss on random test set\n",
    "def test_loss_calculator(gvx,num_nodes, x_dimension, test_per_node):\n",
    "    test_loss = 0\n",
    "    #np.random.seed(2)\n",
    "    np.random.seed(3)\n",
    "    cos_sim_t1 = 0\n",
    "    cos_sim_t2 = 0\n",
    "    cos_sim_t3 = 0\n",
    "    # T1\n",
    "    for i in range(num_nodes):\n",
    "        if i <= 2:\n",
    "            x = gvx.GetNodeValue(i+1,'x')\n",
    "            cos_sim_t1 += np.dot(x,a1) / (sqrt(sum([a*a for a in x]))*sqrt(sum([a*a for a in a1])))\n",
    "            for k in range(test_per_node):\n",
    "                w = np.random.normal(0, 1, n-1)\n",
    "                noise = np.random.normal(0, reg_noise, 1)\n",
    "                y =  np.dot(a1[:x_dimension], w) + a1[x_dimension]\n",
    "                #print(y)\n",
    "                pred_y = np.dot(x[:x_dimension], w) + x[x_dimension]\n",
    "                test_loss += square(pred_y - y)\n",
    "\n",
    "        else:\n",
    "            x = gvx.GetNodeValue(i+1,'x')\n",
    "            cos_sim_t1 += np.dot(x,a2) / (sqrt(sum([a*a for a in x]))*sqrt(sum([a*a for a in a2])))\n",
    "            for k in range(test_per_node):\n",
    "                w = np.random.normal(0, 1, n-1)\n",
    "                noise = np.random.normal(0, reg_noise, 1)\n",
    "                y =  np.dot(a2[:x_dimension], w) + a2[x_dimension]\n",
    "                pred_y = np.dot(x[:x_dimension], w) + x[x_dimension]\n",
    "                test_loss += square(pred_y - y)\n",
    "    # T2            \n",
    "    for i in range(num_nodes):\n",
    "        if i < 2:\n",
    "            x = gvx.GetNodeValue(5+i+1,'x')\n",
    "            cos_sim_t2 += np.dot(x,a1_2) / (sqrt(sum([a*a for a in x]))*sqrt(sum([a*a for a in a1_2])))\n",
    "            for k in range(test_per_node):\n",
    "                w = np.random.normal(0, 1, n-1)\n",
    "                noise = np.random.normal(0, reg_noise, 1)\n",
    "                y =  np.dot(a1_2[:x_dimension], w) + a1_2[x_dimension]\n",
    "                pred_y = np.dot(x[:x_dimension], w) + x[x_dimension]\n",
    "                test_loss += square(pred_y - y)\n",
    "\n",
    "        else:\n",
    "            x = gvx.GetNodeValue(5+i+1,'x')\n",
    "            cos_sim_t2 += np.dot(x,a2_2) / (sqrt(sum([a*a for a in x]))*sqrt(sum([a*a for a in a2_2])))\n",
    "            for k in range(test_per_node):\n",
    "                w = np.random.normal(0, 1, n-1)\n",
    "                noise = np.random.normal(0, reg_noise, 1)\n",
    "                y =  np.dot(a2_2[:x_dimension], w) + a2_2[x_dimension]\n",
    "                pred_y = np.dot(x[:x_dimension], w) + x[x_dimension]\n",
    "                test_loss += square(pred_y - y)\n",
    "    # T3            \n",
    "    for i in range(num_nodes):\n",
    "        if i <= 2:\n",
    "            x = gvx.GetNodeValue(10+i+1,'x')\n",
    "            cos_sim_t3 += np.dot(x,a1_3) / (sqrt(sum([a*a for a in x]))*sqrt(sum([a*a for a in a1_3])))\n",
    "            for k in range(test_per_node):\n",
    "                w = np.random.normal(0, 1, n-1)\n",
    "                noise = np.random.normal(0, reg_noise, 1)\n",
    "                y =  np.dot(a1_3[:x_dimension], w) + a1_3[x_dimension]\n",
    "                pred_y = np.dot(x[:x_dimension], w) + x[x_dimension]\n",
    "                test_loss += square(pred_y - y)\n",
    "\n",
    "        else:\n",
    "            x = gvx.GetNodeValue(10+i+1,'x')\n",
    "            cos_sim_t3 += np.dot(x,a2_3) / (sqrt(sum([a*a for a in x]))*sqrt(sum([a*a for a in a2_3])))\n",
    "            for k in range(test_per_node):\n",
    "                w = np.random.normal(0, 1, n-1)\n",
    "                noise = np.random.normal(0, reg_noise, 1)\n",
    "                y =  np.dot(a2_3[:x_dimension], w) + a2_3[x_dimension]\n",
    "                pred_y = np.dot(x[:x_dimension], w) + x[x_dimension]\n",
    "                test_loss += square(pred_y - y)\n",
    "\n",
    "    print('Test loss', test_loss.value)\n",
    "    print('Similarities: ', cos_sim_t1.value, cos_sim_t2.value, cos_sim_t3.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1 = []\n",
    "noise1 = []\n",
    "w2 = []\n",
    "noise2 = []\n",
    "w3 = []\n",
    "noise3 = []\n",
    "\n",
    "n = 10\n",
    "a1 = np.random.normal(0, 1, n)\n",
    "a2 = np.random.normal(0, 1, n)\n",
    "a1_2 = a1 + np.random.normal(0, 0.1, n)\n",
    "a2_2 = a2 + np.random.normal(0, 0.1, n)\n",
    "a1_3 = a1_2 + np.random.normal(0, 0.1, n)\n",
    "a2_3 = a2_2 + np.random.normal(0, 0.1, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Step :', 0, ' ***')\n",
      "('Solution: ', 11.06637060009453)\n",
      "('F(x)value: ', 3.0379711707928694)\n",
      "('Static edge penalties: ', 1.7476149515625945, 87.380747578129728)\n",
      "('Temporal edge penalties: ', 6.2807844777390658, 31.403922388695328)\n",
      "('Train Loss: ', 1.9155730296498332)\n",
      "('Total Beta loss: ', 1.2764275344565723)\n",
      "('Beta term 1: ', 0.38656309083409263, 1.932815454170463)\n",
      "('Beta term 2: ', 0.0, nan)\n",
      "('Beta term 3:', 2.0572462808178118, 20.572462808178116)\n",
      "('Test loss', 105.98508452947904)\n",
      "('Similarities: ', 4.9673173045592129, 4.8646764000706728, 4.9119021176704152)\n",
      "('**** End of step ', 0, ' ****')\n",
      "('Step :', 1, ' ***')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:300: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Solution: ', 4.543718031707868)\n",
      "('F(x)value: ', 1.8247534837990618)\n",
      "('Static edge penalties: ', 1.8413108479090476, 92.065542395452383)\n",
      "('Temporal edge penalties: ', 0.87765369999975795, 4.3882684999987891)\n",
      "('Train Loss: ', 0.6911729498389614)\n",
      "('Total Beta loss: ', 1.6160633875796928)\n",
      "('Beta term 1: ', 0.48649130560325171, 2.4324565280162584)\n",
      "('Beta term 2: ', 0.0, nan)\n",
      "('Beta term 3:', 2.6956451695345551, 26.95645169534555)\n",
      "('Test loss', 74.18218466607556)\n",
      "('Similarities: ', 4.9649712689809409, 4.9389880994957647, 4.9356977301066305)\n",
      "('**** End of step ', 1, ' ****')\n",
      "('Step :', 2, ' ***')\n",
      "('Solution: ', 4.129757066495905)\n",
      "('F(x)value: ', 1.6672130745360834)\n",
      "('Static edge penalties: ', 1.8710226943553998, 93.551134717769983)\n",
      "('Temporal edge penalties: ', 0.59152129760442207, 2.95760648802211)\n",
      "('Train Loss: ', 0.5337705440281627)\n",
      "('Total Beta loss: ', 1.7032603263342638)\n",
      "('Beta term 1: ', 0.51177540406273503, 2.558877020313675)\n",
      "('Beta term 2: ', 0.0, nan)\n",
      "('Beta term 3:', 2.8710080548704147, 28.710080548704145)\n",
      "('Test loss', 73.26550319969395)\n",
      "('Similarities: ', 4.9598805982131768, 4.9510333629013719, 4.9352792735067936)\n",
      "('**** End of step ', 2, ' ****')\n",
      "('Step :', 3, ' ***')\n",
      "('Solution: ', 4.055185442817236)\n",
      "('F(x)value: ', 1.6274176697680274)\n",
      "('Static edge penalties: ', 1.8817207331327694, 94.08603665663847)\n",
      "('Temporal edge penalties: ', 0.5460470399164391, 2.7302351995821952)\n",
      "('Train Loss: ', 0.49542128698934984)\n",
      "('Total Beta loss: ', 1.7332131627396221)\n",
      "('Beta term 1: ', 0.52035531121953704, 2.6017765560976849)\n",
      "('Beta term 2: ', 0.0, nan)\n",
      "('Beta term 3:', 2.934539841995691, 29.345398419956908)\n",
      "('Test loss', 75.81198441625973)\n",
      "('Similarities: ', 4.9571543132183429, 4.9532209676533761, 4.9314769656128332)\n",
      "('**** End of step ', 3, ' ****')\n",
      "('Step :', 4, ' ***')\n",
      "('Solution: ', 4.035125058141706)\n",
      "('F(x)value: ', 1.6142371776066555)\n",
      "('Static edge penalties: ', 1.88660693860989, 94.3303469304945)\n",
      "('Temporal edge penalties: ', 0.53428094192516107, 2.6714047096258051)\n",
      "('Train Loss: ', 0.48337572749291413)\n",
      "('Total Beta loss: ', 1.7456950432263836)\n",
      "('Beta term 1: ', 0.52384369501857464, 2.6192184750928731)\n",
      "('Beta term 2: ', 0.0, nan)\n",
      "('Beta term 3:', 2.9636265672319713, 29.636265672319713)\n",
      "('Test loss', 78.1687702833745)\n",
      "('Similarities: ', 4.9558352609508711, 4.9532880963529546, 4.9277425225334861)\n",
      "('**** End of step ', 4, ' ****')\n"
     ]
    }
   ],
   "source": [
    "# PARAMETERS \n",
    "saved_variables = True\n",
    "if saved_variables == False:\n",
    "    w1 = []\n",
    "    noise1 = []\n",
    "    w2 = []\n",
    "    noise2 = []\n",
    "    w3 = []\n",
    "    noise3 = []\n",
    "    \n",
    "np.random.seed(2)\n",
    "\n",
    "num_nodes = 5\n",
    "num_edges = 5\n",
    "\n",
    "cons = []\n",
    "\n",
    "total_steps = 5\n",
    "\n",
    "x_dimension = 9 # Actually this means dimension is 10 (0-9)\n",
    "n = 10\n",
    "train_per_node = 10\n",
    "test_per_node = 20\n",
    "reg_noise = 0.1\n",
    "\n",
    "u_reg = 0.01\n",
    "e_pen = 0.02\n",
    "e_lambda = 0.2\n",
    "lambda_1 = 0.2\n",
    "lambda_2 = 0\n",
    "lambda_3 = 0.1\n",
    "\n",
    "m = 2*5 # For beta (# of beta variables)\n",
    "\n",
    "optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Static Example\n",
    "\n",
    "def optimizer():\n",
    "    \n",
    "    for step in range(total_steps):\n",
    "\n",
    "        gvx = TGraphVX()\n",
    "        # T1\n",
    "        #For each node, add an objective\n",
    "        for i in range(num_nodes):\n",
    "            if i <= 2:\n",
    "                x = Variable(n,name='x')\n",
    "                obj = 0 \n",
    "                for k in range(train_per_node):\n",
    "                    if saved_variables:\n",
    "                        w = w1[i*train_per_node+k] #np.random.normal(0, 1, 50) #\n",
    "                        #w1.append(w)\n",
    "                        noise = noise1[i*train_per_node+k] #np.random.normal(0, 0.1, 1) #\n",
    "                        #noise1.append(noise)\n",
    "                    else:\n",
    "                        w = np.random.normal(0, 1, n-1) #w1[i*25+k] #\n",
    "                        w1.append(w)\n",
    "                        noise = np.random.normal(0, reg_noise, 1) #noise1[i*25+k] #\n",
    "                        noise1.append(noise)\n",
    "\n",
    "                    y =  (np.dot(a1[:x_dimension], w) + a1[x_dimension] + noise)#[0]\n",
    "                    pred_y = 0\n",
    "                    for l in range(x_dimension):\n",
    "                        pred_y += x[l]*w[l]\n",
    "                    pred_y += x[x_dimension]\n",
    "                    obj += square(pred_y - y)\n",
    "\n",
    "        #         cons = [-1 <= val for val in x]\n",
    "        #         cons = cons + [1 >= val for val in x]\n",
    "                obj += u_reg*sum_squares(x[:x_dimension])\n",
    "                gvx.AddNode(i+1, obj, cons) \n",
    "            else:\n",
    "                x = Variable(n,name='x')\n",
    "                obj = 0 \n",
    "                for k in range(train_per_node):\n",
    "                    if saved_variables:\n",
    "                        w = w1[i*train_per_node+k] #np.random.normal(0, 1, 50) #\n",
    "                        #w1.append(w)\n",
    "                        noise =  noise1[i*train_per_node+k]#np.random.normal(0, 0.1, 1) #\n",
    "                        #noise1.append(noise)\n",
    "                    else:\n",
    "                        w = np.random.normal(0, 1, n-1) #w1[i*25+k] #\n",
    "                        w1.append(w)\n",
    "                        noise =  np.random.normal(0, reg_noise, 1) #noise1[i*25+k]#\n",
    "                        noise1.append(noise)\n",
    "\n",
    "                    y =  (np.dot(a2[:x_dimension], w) + a2[x_dimension] + noise)#[0]\n",
    "                    pred_y = 0\n",
    "                    for l in range(x_dimension):\n",
    "                        pred_y += x[l]*w[l]\n",
    "                    pred_y += x[x_dimension]\n",
    "                    obj += square(pred_y - y)\n",
    "\n",
    "        #         cons = [-1 <= val for val in x]\n",
    "        #         cons = cons + [1 >= val for val in x]\n",
    "                obj += u_reg*sum_squares(x[:x_dimension])\n",
    "                gvx.AddNode(i+1, obj, cons) \n",
    "        gvx.AddEdge(1,2)\n",
    "        gvx.AddEdge(1,3)\n",
    "        gvx.AddEdge(2,3)\n",
    "        gvx.AddEdge(3,4)\n",
    "        gvx.AddEdge(4,5)\n",
    "\n",
    "        # T2\n",
    "        #For each node, add an objective\n",
    "        for i in range(num_nodes):\n",
    "            if i < 2:\n",
    "                x = Variable(n,name='x')\n",
    "                obj = 0 \n",
    "                for k in range(train_per_node):\n",
    "                    if saved_variables:\n",
    "                        w =  w2[i*train_per_node+k] #np.random.normal(0, 1, 50) #\n",
    "                        #w2.append(w)\n",
    "                        noise = noise2[i*train_per_node+k] #np.random.normal(0, 0.1, 1)#\n",
    "                        #noise2.append(noise)\n",
    "                    else:\n",
    "                        w = np.random.normal(0, 1, n-1) # w2[i*25+k] #\n",
    "                        w2.append(w)\n",
    "                        noise = np.random.normal(0, reg_noise, 1) #noise2[i*25+k] #\n",
    "                        noise2.append(noise)\n",
    "\n",
    "                    y =  (np.dot(a1_2[:x_dimension], w) + a1_2[x_dimension] + noise)#[0]\n",
    "                    pred_y = 0\n",
    "                    for l in range(x_dimension):\n",
    "                        pred_y += x[l]*w[l]\n",
    "                    pred_y += x[x_dimension]\n",
    "                    obj += square(pred_y - y)\n",
    "\n",
    "        #         cons = [-1 <= val for val in x]\n",
    "        #         cons = cons + [1 >= val for val in x]\n",
    "                obj += u_reg*sum_squares(x[:x_dimension])\n",
    "                gvx.AddNode(5+i+1, obj, cons) \n",
    "            else:\n",
    "                x = Variable(n,name='x')\n",
    "                obj = 0 \n",
    "                for k in range(train_per_node):\n",
    "                    if saved_variables:\n",
    "                        w =  w2[i*train_per_node+k] #np.random.normal(0, 1, 50) #\n",
    "                        #w2.append(w)\n",
    "                        noise =  noise2[i*train_per_node+k] #np.random.normal(0, 0.1, 1) #\n",
    "                        #noise2.append(noise)\n",
    "                    else:\n",
    "                        w =  np.random.normal(0, 1, n-1) #w2[i*25+k] #\n",
    "                        w2.append(w)\n",
    "                        noise =  np.random.normal(0, reg_noise, 1) #noise2[i*25+k] #\n",
    "                        noise2.append(noise)\n",
    "\n",
    "                    y =  (np.dot(a2_2[:x_dimension], w) + a2_2[x_dimension] + noise)#[0]\n",
    "                    pred_y = 0\n",
    "                    for l in range(x_dimension):\n",
    "                        pred_y += x[l]*w[l]\n",
    "                    pred_y += x[x_dimension]\n",
    "                    obj += square(pred_y - y)\n",
    "\n",
    "        #         cons = [-1 <= val for val in x]\n",
    "        #         cons = cons + [1 >= val for val in x]\n",
    "                obj += u_reg*sum_squares(x[:x_dimension])\n",
    "                gvx.AddNode(5+i+1, obj, cons) \n",
    "        gvx.AddEdge(6,7)\n",
    "        gvx.AddEdge(6,8)\n",
    "        gvx.AddEdge(7,8)\n",
    "        gvx.AddEdge(8,9)\n",
    "        gvx.AddEdge(9,10)\n",
    "\n",
    "        #T3\n",
    "        #For each node, add an objective\n",
    "        for i in range(num_nodes):\n",
    "            if i <= 2:\n",
    "                x = Variable(n,name='x')\n",
    "                obj = 0 \n",
    "                for k in range(train_per_node):\n",
    "                    if saved_variables:\n",
    "                        w =  w3[i*train_per_node+k] #np.random.normal(0, 1, 50) #\n",
    "                        #w3.append(w)\n",
    "                        noise = noise3[i*train_per_node+k] # np.random.normal(0, 0.1, 1) # \n",
    "                        #noise3.append(noise)\n",
    "                    else:\n",
    "                        w =  np.random.normal(0, 1, n-1) #w3[i*25+k] #\n",
    "                        w3.append(w)\n",
    "                        noise =  np.random.normal(0, reg_noise, 1) # noise3[i*25+k] #\n",
    "                        noise3.append(noise)\n",
    "\n",
    "                    y =  (np.dot(a1_3[:x_dimension], w) + a1_3[x_dimension] + noise)#[0]\n",
    "                    pred_y = 0\n",
    "                    for l in range(x_dimension):\n",
    "                        pred_y += x[l]*w[l]\n",
    "                    pred_y += x[x_dimension]\n",
    "                    obj += square(pred_y - y)\n",
    "\n",
    "        #         cons = [-1 <= val for val in x]\n",
    "        #         cons = cons + [1 >= val for val in x]\n",
    "                obj += u_reg*sum_squares(x[:x_dimension])\n",
    "                gvx.AddNode(10+i+1, obj, cons) \n",
    "            else:\n",
    "                x = Variable(n,name='x')\n",
    "                obj = 0 \n",
    "                for k in range(train_per_node):\n",
    "                    if saved_variables:\n",
    "                        w =  w3[i*train_per_node+k] #np.random.normal(0, 1, 50) #\n",
    "                        #w3.append(w)\n",
    "                        noise =  noise3[i*train_per_node+k] #np.random.normal(0, 0.1, 1) #\n",
    "                        #noise3.append(noise)\n",
    "                    else:\n",
    "                        w =  np.random.normal(0, 1, n-1) #w3[i*25+k] #\n",
    "                        w3.append(w)\n",
    "                        noise =  np.random.normal(0, reg_noise, 1) #noise3[i*25+k] #\n",
    "                        noise3.append(noise)\n",
    "\n",
    "                    y =  (np.dot(a2_3[:x_dimension], w) + a2_3[x_dimension] + noise)#[0]\n",
    "                    pred_y = 0\n",
    "                    for l in range(x_dimension):\n",
    "                        pred_y += x[l]*w[l]\n",
    "                    pred_y += x[x_dimension]\n",
    "                    obj += square(pred_y - y)\n",
    "\n",
    "        #         cons = [-1 <= val for val in x]\n",
    "        #         cons = cons + [1 >= val for val in x]\n",
    "                obj += u_reg*sum_squares(x[:x_dimension])\n",
    "                gvx.AddNode(10+i+1, obj, cons) \n",
    "        gvx.AddEdge(11,12)\n",
    "        gvx.AddEdge(11,13)\n",
    "        gvx.AddEdge(12,13)\n",
    "        gvx.AddEdge(13,14)\n",
    "        gvx.AddEdge(14,15)\n",
    "\n",
    "        gvx.AddEdgeObjectives(laplace_reg)\n",
    "\n",
    "\n",
    "        if step == 0:\n",
    "\n",
    "            gvx.AddEdge(1,6, Objective = e_lambda*sum_squares(gvx.GetNodeVariables(1)['x'] - gvx.GetNodeVariables(6)['x']), Constraints = [])\n",
    "            gvx.AddEdge(2,7, Objective = e_lambda*sum_squares(gvx.GetNodeVariables(2)['x'] - gvx.GetNodeVariables(7)['x']), Constraints = [])\n",
    "            gvx.AddEdge(3,8, Objective = e_lambda*sum_squares(gvx.GetNodeVariables(3)['x'] - gvx.GetNodeVariables(8)['x']), Constraints = [])\n",
    "            gvx.AddEdge(4,9, Objective = e_lambda*sum_squares(gvx.GetNodeVariables(4)['x'] - gvx.GetNodeVariables(9)['x']), Constraints = [])\n",
    "            gvx.AddEdge(5,10, Objective = e_lambda*sum_squares(gvx.GetNodeVariables(5)['x'] - gvx.GetNodeVariables(10)['x']), Constraints = [])\n",
    "            gvx.AddEdge(6,11, Objective = e_lambda*sum_squares(gvx.GetNodeVariables(6)['x'] - gvx.GetNodeVariables(11)['x']), Constraints = [])\n",
    "            gvx.AddEdge(7,12, Objective = e_lambda*sum_squares(gvx.GetNodeVariables(7)['x'] - gvx.GetNodeVariables(12)['x']), Constraints = [])\n",
    "            gvx.AddEdge(8,13, Objective = e_lambda*sum_squares(gvx.GetNodeVariables(8)['x'] - gvx.GetNodeVariables(13)['x']), Constraints = [])\n",
    "            gvx.AddEdge(9,14, Objective = e_lambda*sum_squares(gvx.GetNodeVariables(9)['x'] - gvx.GetNodeVariables(14)['x']), Constraints = [])\n",
    "            gvx.AddEdge(10,15, Objective = e_lambda*sum_squares(gvx.GetNodeVariables(10)['x'] - gvx.GetNodeVariables(15)['x']), Constraints = [])\n",
    "\n",
    "        else:\n",
    "            gvx.AddEdge(1,6, Objective = e_lambda*sum_squares(Betas.value[:,0] + gvx.GetNodeVariables(1)['x'] - gvx.GetNodeVariables(6)['x']), Constraints = [])\n",
    "            gvx.AddEdge(2,7, Objective = e_lambda*sum_squares(Betas.value[:,1] + gvx.GetNodeVariables(2)['x'] - gvx.GetNodeVariables(7)['x']), Constraints = [])\n",
    "            gvx.AddEdge(3,8, Objective = e_lambda*sum_squares(Betas.value[:,2] + gvx.GetNodeVariables(3)['x'] - gvx.GetNodeVariables(8)['x']), Constraints = [])\n",
    "            gvx.AddEdge(4,9, Objective = e_lambda*sum_squares(Betas.value[:,3] + gvx.GetNodeVariables(4)['x'] - gvx.GetNodeVariables(9)['x']), Constraints = [])\n",
    "            gvx.AddEdge(5,10, Objective = e_lambda*sum_squares(Betas.value[:,4] + gvx.GetNodeVariables(5)['x'] - gvx.GetNodeVariables(10)['x']), Constraints = [])\n",
    "            gvx.AddEdge(6,11, Objective = e_lambda*sum_squares(Betas.value[:,5] + gvx.GetNodeVariables(6)['x'] - gvx.GetNodeVariables(11)['x']), Constraints = [])\n",
    "            gvx.AddEdge(7,12, Objective = e_lambda*sum_squares(Betas.value[:,6] + gvx.GetNodeVariables(7)['x'] - gvx.GetNodeVariables(12)['x']), Constraints = [])\n",
    "            gvx.AddEdge(8,13, Objective = e_lambda*sum_squares(Betas.value[:,7] + gvx.GetNodeVariables(8)['x'] - gvx.GetNodeVariables(13)['x']), Constraints = [])\n",
    "            gvx.AddEdge(9,14, Objective = e_lambda*sum_squares(Betas.value[:,8] + gvx.GetNodeVariables(9)['x'] - gvx.GetNodeVariables(14)['x']), Constraints = [])\n",
    "            gvx.AddEdge(10,15, Objective = e_lambda*sum_squares(Betas.value[:,9] + gvx.GetNodeVariables(10)['x'] - gvx.GetNodeVariables(15)['x']), Constraints = [])\n",
    "\n",
    "\n",
    "        # Graph is ready, now solve it!!\n",
    "        print('Step :', step, ' ***')\n",
    "        t_0 = time.time()\n",
    "        gvx.Solve()\n",
    "        t_1 = time.time()\n",
    "\n",
    "    #     print('Total time passed: ', str(t_1-t_0))\n",
    "        print('Solution: ', gvx.value)\n",
    "\n",
    "        # Split loss into terms\n",
    "\n",
    "        edge_penalties = 0\n",
    "        for ei in gvx.Edges():\n",
    "            src_id = ei.GetSrcNId()\n",
    "            src_vars = gvx.GetNodeValue(src_id, 'x')\n",
    "            dst_id = ei.GetDstNId()\n",
    "            dst_vars = gvx.GetNodeValue(dst_id, 'x')\n",
    "            edge_diff = src_vars - dst_vars\n",
    "            edge_penalties += sum([x*x for x in edge_diff])\n",
    "\n",
    "        B_term_1_T = 0\n",
    "        B_term_1 = 0\n",
    "        for i in range(10):\n",
    "            penalties_B_X = gvx.GetNodeValue(i+1,'x') - gvx.GetNodeValue(i+1+5,'x')\n",
    "            if step == 0:\n",
    "                penalties_B_X_T = penalties_B_X\n",
    "            else:\n",
    "                penalties_B_X_T = np.squeeze(np.asarray(Betas.value[:,i])) + gvx.GetNodeValue(i+1,'x') - gvx.GetNodeValue(i+1+5,'x')\n",
    "            B_term_1 += sum([x*x for x in penalties_B_X])\n",
    "            B_term_1_T += e_lambda*sum([x*x for x in penalties_B_X_T])\n",
    "\n",
    "        edge_penalties = edge_penalties -  B_term_1   \n",
    "        print ('F(x)value: ', gvx.value - B_term_1_T - e_pen*edge_penalties)\n",
    "        print ('Static edge penalties: ', e_pen*edge_penalties, edge_penalties)\n",
    "        print ('Temporal edge penalties: ', B_term_1_T,  B_term_1_T/e_lambda) \n",
    "        train_loss_calculator(gvx, num_nodes, x_dimension, train_per_node)\n",
    "\n",
    "\n",
    "\n",
    "        # Construct the problem.\n",
    "        Betas = Variable(n,m)\n",
    "        total_loss = 0\n",
    "        for i in range(m):\n",
    "            total_loss += lambda_1*sum_squares(Betas[:,i] + gvx.GetNodeValue(i+1,'x') - gvx.GetNodeValue(i+1+5,'x')) \n",
    "        for i in range(m/2):\n",
    "            total_loss +=  lambda_2*sum_squares(Betas[:,i] - Betas[:,i+5])\n",
    "        for i in range(m/2):\n",
    "            total_loss +=  lambda_3*(sum_squares(Betas[:,i]) + lambda_3*sum_squares(Betas[:,i+5]))  \n",
    "\n",
    "\n",
    "        objective = Minimize(total_loss)\n",
    "        constraints = []\n",
    "        # for i in range(n):\n",
    "        #     for j in range(m):\n",
    "        #         constraints = constraints + [-1 <= Betas[i,j], Betas[i,j] <= 1]\n",
    "        prob = Problem(objective, constraints)\n",
    "\n",
    "        # The optimal objective is returned by prob.solve().\n",
    "        result = prob.solve()\n",
    "        # The optimal value for x is stored in x.value.\n",
    "\n",
    "        print ('Total Beta loss: ', result)\n",
    "\n",
    "        # Penalty for each term\n",
    "        Beta_term_1 = 0\n",
    "        for i in range(m):\n",
    "            penalties_B_X = np.squeeze(np.asarray(Betas.value[:,i])) + gvx.GetNodeValue(i+1,'x') - gvx.GetNodeValue(i+1+5,'x')\n",
    "        #     print('**', gvx.GetNodeValue(i+1,'x').shape)\n",
    "        #     print('**', type(gvx.GetNodeValue(i+1,'x')))\n",
    "        #     print('**', np.squeeze(np.asarray(Betas.value[:,i])).shape)\n",
    "\n",
    "        #     print('**', type(np.squeeze(np.asarray(Betas.value[:,i]))))\n",
    "        #     print('*****', penalties_B_X.shape)\n",
    "            Beta_term_1 += lambda_1*sum([x*x for x in penalties_B_X]) \n",
    "            #B_term_1 += lambda_1*sum([x*x for x in (Betas.value[:,i] + gvx.GetNodeValue(i+1,'x') - gvx.GetNodeValue(i+1+5,'x'))])\n",
    "        print('Beta term 1: ', Beta_term_1, Beta_term_1/lambda_1)\n",
    "\n",
    "        Beta_term_2 = 0\n",
    "        for i in range(m/2):\n",
    "            Beta_term_2 += lambda_2*sum([x*x for x in np.squeeze(np.asarray(Betas.value[:,i]))-np.squeeze(np.asarray(Betas.value[:,i+5]))]) \n",
    "        print('Beta term 2: ', Beta_term_2, Beta_term_2/lambda_2)\n",
    "\n",
    "        Beta_term_3 = 0\n",
    "        for i in range(m/2):\n",
    "            Beta_term_3 += lambda_3*sum([x*x for x in np.squeeze(np.asarray(Betas.value[:,i]))]) + lambda_3*sum([x*x for x in np.squeeze(np.asarray(Betas.value[:,i+5]))])\n",
    "        print('Beta term 3:', Beta_term_3, Beta_term_3/lambda_3)\n",
    "\n",
    "        # TEST RESULTS\n",
    "        test_loss_calculator(gvx, num_nodes, x_dimension, test_per_node)\n",
    "\n",
    "        print('**** End of step ', step, ' ****')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.21934199  1.14876025 -2.02531503  0.51868094 -0.51156381  0.04516914 -1.39725192 -1.51603688 -0.21488301  0.80664517]\n",
      "[-1.2615938   1.09137959 -1.93942279  0.40620766 -0.44262555  0.11306742 -1.39024369 -1.59249626 -0.14734546  0.74577395]\n",
      "[-1.18498659  1.04087914 -1.93869227  0.49726456 -0.36420058  0.05904555 -1.37179706 -1.43416436 -0.06028504  0.72441626]\n"
     ]
    }
   ],
   "source": [
    "print a1\n",
    "print a1_2\n",
    "print a1_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.21934199  1.14876025 -2.02531503  0.51868094 -0.51156381  0.04516914 -1.39725192 -1.51603688 -0.21488301  0.80664517]\n",
      "[-0.10206231 -0.40832492  0.56035034  1.23963256  0.4119495  -0.96362254  1.11129942  0.82088491  0.72447633  2.31822846]\n",
      "0.222248858023\n",
      "Status: Optimal\n",
      "Total Objective: 0.222249\n",
      "Node 1:\n",
      "  x [-1.35533764  1.10398749 -2.11261016  0.37402481 -0.43526707 -0.13863326 -1.33673326 -1.53994057  0.03014576  0.89174653]\n",
      "Node 2:\n",
      "  x [-1.01395101  0.76985598 -1.97011223  0.58996421 -0.32420073  0.34788771 -1.4184618  -1.44984935  0.04749832  0.23489931]\n",
      "Node 3:\n",
      "  x [-1.11870559  1.23608127 -2.05796139  0.61791075 -0.49090426  0.26506921 -1.33259232 -1.45780743 -0.18421887  0.96844362]\n",
      "Node 4:\n",
      "  x [-0.29519811 -0.65875112  0.38464374  1.11349688  0.64602817 -0.23687129  0.89841013  0.54795337  0.3545761   2.5181651 ]\n",
      "Node 5:\n",
      "  x [-0.15900468 -0.51592266  0.53096641  1.43096258  0.58874562 -1.05550622  1.12538348  0.67213039  0.66821881  2.0782236 ]\n",
      "Node 6:\n",
      "  x [-1.224108    1.3705255  -1.34360515  0.51207323 -0.3137029   0.45994339 -1.14588791 -1.58450171  0.02195829  0.72055545]\n",
      "Node 7:\n",
      "  x [-0.95775348  0.81949588 -1.74854738  0.59650966 -0.11398363 -0.17282929 -1.46062609 -1.72093856 -0.31461737  0.82252236]\n",
      "Node 8:\n",
      "  x [-0.1873136  -0.42765329  0.69032537  1.135604    0.24402677 -0.86636866  1.1603265   0.73248023  0.67315109  2.1822697 ]\n",
      "Node 9:\n",
      "  x [-0.28229593 -0.53614438  0.23265872  1.32077376  0.24321698 -0.98878139  0.73783003  0.82170121  0.45585467  1.87739657]\n",
      "Node 10:\n",
      "  x [-0.21873551 -0.52734762  0.76018305  1.28037362  0.40229414 -0.98412229  1.08390972  0.62427998  0.63203799  2.27491771]\n",
      "Node 11:\n",
      "  x [-1.17725572  0.93801985 -1.8059334   0.30519198 -0.44680301  0.02513498 -1.17537176 -1.42363121  0.15715443  0.71783044]\n",
      "Node 12:\n",
      "  x [-0.58233932  0.22563199 -1.25704966  0.42489207 -1.3622883  -0.56942364 -1.4689275  -1.08760851 -0.35888436  0.47668809]\n",
      "Node 13:\n",
      "  x [-1.39071564  0.77300352 -1.67727331  0.62445815 -0.39144187  0.28011699 -1.10741251 -1.5655207  -0.35706044  0.90677991]\n",
      "Node 14:\n",
      "  x [-0.24227664 -0.82226679  0.69811363  1.01437819  0.31163245 -1.08472544  1.04266944  0.69408855  0.81991471  2.36126687]\n",
      "Node 15:\n",
      "  x [-0.13162488 -0.56612185  0.65727791  1.06349717  0.37744112 -1.08939478  1.08002414  0.74577477  0.69539334  2.35664072]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# t_0 = time.time()\n",
    "# gvx.Solve()\n",
    "# t_1 = time.time()\n",
    "print a1\n",
    "print a1_2\n",
    "print a1_3\n",
    "print a2\n",
    "print gvx.value\n",
    "print gvx.PrintSolution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('F(x)value: ', 70.012817462153635)\n",
      "('Edge penalties: ', 241.97030450680597)\n",
      "('Temporal edge penalties: ', 147.04330625792039)\n"
     ]
    }
   ],
   "source": [
    "regression_penalties = 0\n",
    "## ToDo -- Penalty check\n",
    "\n",
    "edge_penalties = 0\n",
    "for ei in gvx.Edges():\n",
    "    src_id = ei.GetSrcNId()\n",
    "    src_vars = gvx.GetNodeValue(src_id, 'x')\n",
    "    dst_id = ei.GetDstNId()\n",
    "    dst_vars = gvx.GetNodeValue(dst_id, 'x')\n",
    "    edge_diff = src_vars - dst_vars\n",
    "    #if abs(src_id - dst_id) != 5:  \n",
    "         \n",
    "    edge_penalties += sum([x*x for x in edge_diff])\n",
    "\n",
    "B_term_1_T = 0\n",
    "B_term_1 = 0\n",
    "for i in range(10):\n",
    "    penalties_B_X = gvx.GetNodeValue(i+1,'x') - gvx.GetNodeValue(i+1+5,'x')\n",
    "    penalties_B_X_T = np.squeeze(np.asarray(Betas.value[:,i])) + gvx.GetNodeValue(i+1,'x') - gvx.GetNodeValue(i+1+5,'x')\n",
    "    B_term_1 += sum([x*x for x in penalties_B_X])\n",
    "    B_term_1_T += r2*sum([x*x for x in penalties_B_X_T])\n",
    "    \n",
    "edge_penalties = edge_penalties -  B_term_1   \n",
    "print ('F(x)value: ', gvx.value - B_term_1_T - edge_penalties)\n",
    "print ('Edge penalties: ', edge_penalties)\n",
    "print ('Temporal edge penalties: ', B_term_1_T ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.26295542e-02   1.98918738e-02   4.34248306e-02  -1.69415127e-02  -3.09680885e-03  -1.75771153e-03   2.45820347e-04  -2.03281413e-03  -8.27223807e-04  -6.51555690e-04]\n",
      " [ -1.49277434e-02  -2.56448828e-02  -1.16713467e-01  -3.89392440e-02  -9.98736682e-03   5.29623471e-04  -1.04976861e-03   2.17950503e-03   1.07126462e-03  -5.63831621e-04]\n",
      " [  3.88460261e-02  -2.41815095e-02   3.59910066e-02  -1.66907654e-02   1.41720409e-02   1.57744440e-03   2.27466047e-04   1.44049726e-03  -1.94549499e-03   2.78610388e-04]\n",
      " [  1.92377786e-02  -3.65448141e-03   8.53660627e-02  -2.68074766e-02  -6.72575706e-03  -8.82240119e-04   1.42677633e-03   1.52936714e-03   2.83670828e-03  -3.99173723e-04]\n",
      " [ -4.40583286e-02  -6.94035434e-03  -1.42379573e-02   3.35978697e-03  -1.74482095e-02   6.27975647e-04  -1.17736987e-03   9.55846824e-05  -3.56697910e-04  -1.49628733e-03]\n",
      " [  1.76889609e-02  -1.89912208e-02  -6.35886781e-02  -1.10165317e-02   2.05750522e-03  -1.02106073e-03  -1.32529198e-04  -2.63139821e-03   6.07921206e-04  -2.63129830e-04]\n",
      " [  8.17232180e-03   7.04606852e-03   3.07633261e-02  -3.83586867e-03  -2.21848748e-02  -1.34823974e-03  -1.63473863e-03   4.56413031e-03   1.22955900e-03  -2.78619132e-04]\n",
      " [ -3.34251742e-02   5.19772945e-03  -4.20121091e-02   7.97178140e-03  -5.30259585e-03  -3.02298448e-04  -2.51064843e-04  -1.42926307e-03   2.79099451e-03   1.04226799e-03]\n",
      " [ -2.77244209e-02  -3.07261096e-03   5.07816518e-03  -8.29468573e-03  -1.94113352e-02  -1.07006979e-03  -1.90826129e-03  -1.12562478e-03   9.73093850e-04  -6.10726597e-04]\n",
      " [ -1.19412276e-02  -9.79063465e-03   6.95889069e-02   4.28139900e-02   1.07668274e-02  -3.94769560e-03  -2.05873201e-03  -1.15003003e-02  -2.83109959e-03   3.67848372e-04]\n",
      " [ -3.10399560e-02  -2.88007498e-02  -4.54657621e-02  -7.05908352e-03  -2.86701275e-04  -3.97849210e-03  -5.20242848e-03  -3.05815373e-03  -1.70704051e-03   1.67265728e-04]\n",
      " [  2.67003026e-03  -1.48893893e-02  -4.89486586e-02   2.52592169e-02   1.63458213e-03   1.73431884e-03   4.09812784e-04   5.50185562e-03  -1.00531492e-03  -4.65748843e-04]\n",
      " [ -4.93858883e-02   2.83377327e-02  -1.45841093e-01  -3.15799459e-02   8.08562782e-04   9.93078207e-05  -8.35457203e-04  -5.29167094e-03  -5.75343473e-03  -6.00924476e-04]\n",
      " [ -4.35349559e-02  -1.39537491e-02   6.79750067e-03  -1.00195787e-02  -2.76330001e-04  -5.77093921e-04  -1.99085717e-03   2.47512906e-03  -9.14092025e-04  -3.24017502e-05]\n",
      " [ -3.42135944e-04  -3.36991030e-02  -2.21511270e-02  -8.75976910e-04  -7.68893958e-03  -1.76928360e-03  -1.64143976e-03  -2.39553642e-03  -2.48136185e-03  -4.49882983e-04]\n",
      " [ -3.46555773e-02   4.13607449e-03  -1.83835178e-01  -4.29794678e-02  -2.37108602e-02   2.64184486e-03   2.08777108e-03   1.66289424e-02   1.61051914e-03  -4.11349670e-04]\n",
      " [ -6.47280968e-03  -6.96981556e-03  -5.19989243e-02  -3.49717825e-02  -1.09772963e-02  -7.27111053e-04   1.49216269e-03  -7.03841153e-03  -3.04867828e-03   5.14639666e-05]\n",
      " [ -1.98513801e-02   3.70941411e-03  -8.88408281e-02   1.31927667e-02   1.39398512e-02  -2.72290225e-03  -1.76813189e-03  -3.26516788e-04   3.55222486e-04   8.82227330e-04]\n",
      " [ -1.00911144e-02  -5.65341819e-03  -7.11933206e-02   2.67075085e-02   7.50345897e-03  -1.98906735e-03   6.78795467e-04   8.00735348e-03   2.13799127e-03   5.80911960e-04]\n",
      " [ -1.64486440e-02  -3.37446279e-03  -1.86760797e-01  -2.66014011e-03  -1.05111543e-02   1.82666879e-03  -2.07455829e-03   1.21299631e-02   1.20776558e-03  -7.84649974e-04]\n",
      " [ -3.01030634e-02  -3.40913699e-02  -7.02696471e-02  -6.26915522e-02   1.02354118e-03  -2.29263878e-04  -2.86139472e-04  -4.54010927e-04  -2.51552770e-03  -8.92855736e-04]\n",
      " [  1.64947753e-02   1.28233279e-02  -3.30595225e-02   3.97624703e-02   1.22206702e-02  -6.63595835e-04  -2.81439258e-03  -9.72732918e-04  -7.34711178e-04  -6.19762652e-04]\n",
      " [  1.38274944e-02   6.73226676e-03   7.38088122e-02  -3.58257784e-03  -9.55576251e-03   2.21217039e-03   2.66958128e-03   7.07382048e-03  -4.31960341e-04   6.52669384e-04]\n",
      " [ -2.35679759e-02  -5.38005802e-03   7.57876699e-02   1.16026823e-02  -1.23885609e-02   8.62714372e-05  -2.62698588e-03  -2.85184955e-03  -8.28793082e-04   1.22082257e-03]\n",
      " [  3.85102604e-02   1.00879762e-02   5.31840708e-02  -1.16023083e-03  -3.03265930e-03  -8.67214099e-04  -1.86556735e-03  -3.18763588e-04   6.37936434e-04  -3.37153193e-04]\n",
      " [  2.19157388e-02  -1.21274044e-02  -4.14928794e-02   5.17597738e-03   9.63357050e-03  -7.25491059e-04   3.78383902e-04  -1.43766380e-04   9.55745822e-04  -9.54023852e-04]\n",
      " [ -3.12056683e-02  -9.84230150e-03   1.45056050e-01   1.86708221e-02   6.26159248e-03  -1.92172150e-04  -3.40261107e-04  -4.53241278e-03  -2.84192366e-03  -7.45580025e-06]\n",
      " [  1.33677129e-02   1.78166322e-02  -6.27840005e-03   1.26685774e-02  -1.61469948e-02  -9.55670909e-04   4.47357722e-04   3.68285801e-03   1.87224664e-03   7.96157849e-04]\n",
      " [  1.80582743e-02   2.95708461e-02   1.31081043e-01   2.04214046e-02  -7.83669698e-03  -6.70416061e-04  -2.06922809e-04   2.34777743e-03   1.80329625e-03   2.65127810e-04]\n",
      " [  9.29875903e-03  -1.46619386e-04  -4.17100238e-02  -1.88616499e-02  -1.25478783e-02  -2.00055027e-03   2.51732841e-03   3.50215637e-03  -2.26052238e-04  -1.12638533e-03]\n",
      " [  2.15438573e-02   3.38632873e-03   2.13794243e-02  -4.91451153e-02  -1.31669437e-02   1.61812288e-03   1.27519735e-03   7.73959354e-03  -2.92844354e-03   3.38281518e-05]\n",
      " [  6.10413110e-03  -1.65775088e-03  -5.59238881e-02  -8.60495533e-03  -5.07993156e-03  -8.13763282e-04   9.80484091e-04   3.48223006e-03  -1.83985976e-03   2.73348582e-04]\n",
      " [ -3.31290129e-02   1.40034868e-02  -6.00237547e-02  -4.64898814e-02  -1.33393452e-02  -6.97374486e-04  -2.72622479e-03  -1.02216032e-02  -7.90321439e-04  -2.90497805e-03]\n",
      " [ -2.56929804e-02  -2.44209949e-02  -1.09949338e-01   1.62590516e-02  -1.08693957e-02  -1.27186963e-03  -2.05432336e-04  -4.96375385e-03  -7.11957622e-04  -9.06664922e-04]\n",
      " [  2.55344315e-03   1.10408696e-02   5.51714970e-03   1.94445398e-02   3.07404475e-03   2.41556725e-05   2.06351898e-03  -1.48910637e-03  -1.78517205e-03   3.17525699e-04]\n",
      " [  2.77572791e-02  -2.03861885e-03   3.48123096e-02  -1.79760393e-02   7.22528728e-03   1.42498868e-03   1.04308221e-03   3.97891967e-03   6.12913796e-04   1.38518666e-04]\n",
      " [ -3.03958932e-02   1.28974098e-02   1.23903637e-01   2.86003038e-02   1.69462997e-02   1.30791509e-03   3.37969366e-03   6.63307884e-03   1.17395624e-04   9.11477946e-04]\n",
      " [ -1.45216431e-02  -1.76292149e-02   1.16301888e-01   1.22046844e-02  -6.11263127e-03  -2.72223522e-04  -3.39138546e-03  -7.36428692e-03   1.85168388e-04   8.21306708e-04]\n",
      " [  1.51158878e-02   2.05936639e-02   4.21175487e-02  -2.83873809e-02  -9.32487762e-03   2.49014903e-03   1.33935445e-03   3.16314926e-03  -5.19466061e-04   1.00776713e-04]\n",
      " [ -4.15630824e-03  -2.38681998e-03  -6.00007150e-02   7.13666295e-04  -4.21261236e-03   1.44747214e-03  -5.76585642e-04   1.64946636e-03   3.79940057e-03   1.16052704e-03]\n",
      " [ -1.26786524e-02  -1.70881403e-02  -6.58225335e-02  -3.53362423e-02  -8.83897607e-03  -3.04938788e-04  -1.85223119e-03  -2.01848032e-03  -3.93183558e-03  -9.12818470e-04]\n",
      " [ -7.59938952e-03  -2.14197725e-02   2.29459386e-01   5.99924477e-03  -1.34906199e-02  -7.20814431e-04  -2.69751474e-05  -1.41748073e-02  -3.16255022e-03  -1.29838151e-03]\n",
      " [ -1.83953636e-02  -9.96352410e-03  -1.68262479e-01  -2.45442318e-02  -9.31201423e-03   1.26368742e-03   1.99110931e-03   5.67666599e-03  -3.88527750e-03  -1.34888023e-03]\n",
      " [ -5.84060148e-03   5.26672758e-03  -6.92044212e-02   3.42020896e-02   1.23827574e-02   1.05353035e-03   4.92398526e-04   1.62227953e-03   2.56272908e-03   7.62579424e-04]\n",
      " [ -3.29128774e-02  -6.00337703e-03   1.17297685e-02  -3.94437923e-02  -2.36597136e-02  -2.02287423e-03  -4.30295359e-04  -2.69342464e-03  -1.47343786e-03  -3.19169698e-04]\n",
      " [  1.90487422e-02   4.69141169e-02   5.23951219e-02  -6.72277764e-03   4.72646512e-03   2.52088241e-04   8.41524592e-04   1.01572058e-03   3.07881159e-03   1.07972144e-03]\n",
      " [  3.40171546e-03  -9.55915226e-03  -1.32991762e-01  -5.35722626e-02  -2.15806689e-03   1.98416121e-03   7.46751503e-04   4.39103782e-03  -3.87407007e-03  -1.75793195e-04]\n",
      " [ -1.22110638e-02   2.63632198e-02   8.26827159e-02   2.30893799e-02  -1.05995780e-02   2.12691436e-03   3.53627110e-05   6.42919617e-04   2.38628703e-03  -7.05717721e-04]\n",
      " [ -2.30698945e-03   3.79851825e-02  -2.04041948e-02  -1.84580697e-02   8.39100166e-03  -5.02516904e-04   1.66045658e-03  -3.85622209e-03   8.44941543e-05  -1.27562175e-03]\n",
      " [ -1.83346805e-02   9.99121078e-03  -7.67997690e-02  -1.40550545e-02  -1.05000202e-02   2.28946756e-03   1.29079106e-03   7.29532211e-03   1.86392244e-05   6.91259029e-04]\n",
      " [ -2.65803256e-02   3.41287994e-02  -1.08989259e-01   7.39461365e-04  -1.03263611e-02  -1.13263251e-03   1.03235884e-03   1.38728926e-02   3.11761543e-03  -2.05074999e-04]]\n",
      "159.592104643\n",
      "146.48993219 29.2979864381\n",
      "2.5174860903 0.50349721806\n",
      "9.70588136834 0.485294068417\n"
     ]
    }
   ],
   "source": [
    "#5.0407725617 ---- 1st\n",
    "#5.62140839552 --- 2nd\n",
    "#5.68026627551 --- 3rd\n",
    "#5.68204513814 --- 4th\n",
    "#5.68023002292 --- 5th\n",
    "\n",
    "\n",
    "\n",
    "# Beta update \n",
    "from cvxpy import *\n",
    "\n",
    "m = 2*5\n",
    "lambda_1 = 5\n",
    "lambda_2 = 5\n",
    "lambda_3 = 20\n",
    "\n",
    "# Construct the problem.\n",
    "Betas = Variable(n,m)\n",
    "total_loss = 0\n",
    "for i in range(m):\n",
    "    total_loss += lambda_1*sum_squares(Betas[:,i] + gvx.GetNodeValue(i+1,'x') - gvx.GetNodeValue(i+1+5,'x')) \n",
    "for i in range(m/2):\n",
    "    total_loss +=  lambda_2*sum_squares(Betas[:,i] - Betas[:,i+5])\n",
    "for i in range(m/2):\n",
    "    total_loss +=  lambda_3*(sum_squares(Betas[:,i]) + lambda_3*sum_squares(Betas[:,i+5]))  \n",
    "    \n",
    "    \n",
    "objective = Minimize(total_loss)\n",
    "constraints = []\n",
    "# for i in range(n):\n",
    "#     for j in range(m):\n",
    "#         constraints = constraints + [-1 <= Betas[i,j], Betas[i,j] <= 1]\n",
    "prob = Problem(objective, constraints)\n",
    "\n",
    "# The optimal objective is returned by prob.solve().\n",
    "result = prob.solve()\n",
    "# The optimal value for x is stored in x.value.\n",
    "print Betas.value\n",
    "print result\n",
    "\n",
    "# Penalty for each term\n",
    "B_term_1 = 0\n",
    "for i in range(m):\n",
    "    penalties_B_X = np.squeeze(np.asarray(Betas.value[:,i])) + gvx.GetNodeValue(i+1,'x') - gvx.GetNodeValue(i+1+5,'x')\n",
    "#     print('**', gvx.GetNodeValue(i+1,'x').shape)\n",
    "#     print('**', type(gvx.GetNodeValue(i+1,'x')))\n",
    "#     print('**', np.squeeze(np.asarray(Betas.value[:,i])).shape)\n",
    "    \n",
    "#     print('**', type(np.squeeze(np.asarray(Betas.value[:,i]))))\n",
    "#     print('*****', penalties_B_X.shape)\n",
    "    B_term_1 += lambda_1*sum([x*x for x in penalties_B_X]) \n",
    "    #B_term_1 += lambda_1*sum([x*x for x in (Betas.value[:,i] + gvx.GetNodeValue(i+1,'x') - gvx.GetNodeValue(i+1+5,'x'))])\n",
    "print B_term_1, B_term_1/lambda_1\n",
    "\n",
    "B_term_2 = 0\n",
    "for i in range(m/2):\n",
    "    B_term_2 += lambda_2*sum([x*x for x in np.squeeze(np.asarray(Betas.value[:,i]))-np.squeeze(np.asarray(Betas.value[:,i+5]))]) \n",
    "print B_term_2, B_term_2/lambda_2\n",
    "\n",
    "B_term_3 = 0\n",
    "for i in range(m/2):\n",
    "    B_term_3 += lambda_3*sum([x*x for x in np.squeeze(np.asarray(Betas.value[:,i]))]) + lambda_3*sum([x*x for x in np.squeeze(np.asarray(Betas.value[:,i+5]))])\n",
    "print B_term_3, B_term_3/lambda_3\n",
    "\n",
    "\n",
    "# for i in range(m-1):\n",
    "#     print sum_squares(Betas.value[i] + gvx.GetNodeValue(i+1,'x') - gvx.GetNodeValue(i+1+5,'x'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "('Test loss', 1597.1589044734537)\n",
    "(4.6390697191558994, 4.5192505319485665, 4.6468855885800799)\n",
    "\n",
    "\n",
    "1070.81680168\n",
    "(4.6112358988745248, 4.4627492857107658, 4.6045172994488848)\n",
    "\n",
    "1070.5091783\n",
    "(4.6113762295512988, 4.4627710941571834, 4.6046484242617085)\n",
    "\n",
    "1126.44861123\n",
    "(4.6113762295512988, 4.4627710941571834, 4.6046484242617085)\n",
    "\n",
    "1116.62563086\n",
    "(4.6169247325836524, 4.4637415227009818, 4.6098673764359601)\n",
    "\n",
    "1089.63456755\n",
    "(4.629792461749247, 4.4674968042281584, 4.6222263455145631)\n",
    "\n",
    "971.393364363\n",
    "(4.6738540920039915, 4.4825248898792323, 4.6683964955719235)\n",
    "\n",
    "## OLD\n",
    "1125.79594642\n",
    "(4.6117961200353648, 4.4627982948685299, 4.6050293987880382)\n",
    "\n",
    "\n",
    "\n",
    "#After fixing matrices into w1,2,3 \n",
    "\n",
    "1962.66171305\n",
    "(4.4530182454240963, 4.3606203893919417, 4.5481922347812347)\n",
    "\n",
    "738.768400796\n",
    "(4.8115068166077952, 4.7171492479275221, 4.820396509247038)\n",
    "\n",
    "# Before fixing matrices (This only makes difference when we compute 3 time-stamps seperately)\n",
    "1-None reg losses\n",
    "    564.581292151\n",
    "    664.937592784\n",
    "    633.651325366\n",
    "    \n",
    "2396.97950807\n",
    "(4.5032426481896266, 4.2483433083711679, 4.5010646180521636)\n",
    "\n",
    "1-1 reg losses\n",
    "681.904237346\n",
    "(4.8509831274086652, 4.7536483914568501, 4.8078107786076938)\n",
    "\n",
    "1-2 reg losses\n",
    "605.136647142\n",
    "(4.8617645377740972, 4.7683566754155873, 4.8292656134070828)\n",
    "\n",
    "1-5 reg losses\n",
    "583.3718383\n",
    "(4.8511840764512231, 4.7567723302765241, 4.8295890235273813)\n",
    "\n",
    "1-10 reg losses\n",
    "617.937627281\n",
    "(4.833551277367877, 4.7392154973538547, 4.817418998869897)\n",
    "\n",
    "1-20 reg losses\n",
    "676.817453536\n",
    "(4.8147970926407293, 4.7148278275907352, 4.8009750561378004)\n",
    "\n",
    "1-50 reg losses\n",
    "758.443589006\n",
    "(4.7950783052833623, 4.6859704146739647, 4.7820063925131961)\n",
    "\n",
    "1-100 reg losses\n",
    "804.63887356\n",
    "(4.7858791086269967, 4.6711083189084519, 4.7726741002856636)\n",
    "\n",
    "1-1000 reg losses\n",
    "862.128245312\n",
    "(4.7756824176180039, 4.6536593532870043, 4.7620667971216664)\n",
    "\n",
    "1-1000000 reg losses\n",
    "873.406994009\n",
    "(4.7739094931355179, 4.6503579147692902, 4.7601167319753817)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.42815302  4.98672723]\n",
      "[ 1.41489249 -7.53147357]\n",
      "[-2.89300126  8.25718269]\n",
      "[-12.13339622  -2.14456314]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "rnd1 = np.random.normal(0, 5, 2)\n",
    "print(rnd1)\n",
    "rnd2 = np.random.normal(0, 5, 2)\n",
    "print(rnd2)\n",
    "rnd3 = np.random.normal(0, 5, 2)\n",
    "print(rnd3)\n",
    "rnd4 = np.random.normal(0, 5, 2)\n",
    "print(rnd4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.42815302  4.98672723]\n",
      "[ 1.41489249 -7.53147357]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "rnd2 = np.random.normal(0, 5, 2)\n",
    "print(rnd2)\n",
    "rnd4 = np.random.normal(0, 5, 2)\n",
    "print(rnd4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
